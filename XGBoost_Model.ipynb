{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import Standard Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv file\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# display first 5 rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Convert Categorical Features to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical variables\n",
    "label_encoder = {}\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoder[col] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Define Features (X) and Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define predictor variables\n",
    "X = df.drop(columns=['category'])\n",
    "\n",
    "# define target variable\n",
    "y = df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    train_size=0.8, \n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameter Grid for Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'subsample': [0.5, 0.8, 1],\n",
    "    'colsample_bytree': [0.5, 0.8, 1],\n",
    "    'gamma': [0, 0.1, 0.3]\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform GridSearch with 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize XGBoost Model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m xgb_clf \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241m.\u001b[39mXGBClassifier(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softmax\u001b[39m\u001b[38;5;124m'\u001b[39m, num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Use GridSearchCV to find the best hyperparameters\u001b[39;00m\n\u001b[0;32m      5\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m      6\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mxgb_clf, \n\u001b[0;32m      7\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# use all available CPU cores\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize XGBoost Model\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', num_class=3, random_state=42)\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_clf, \n",
    "    param_grid=param_grid, \n",
    "    scoring='accuracy',\n",
    "    cv=5, \n",
    "    n_jobs=-1, # use all available CPU cores\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GridSearchCV\n",
    "grid_search.fit(train_x, train_y)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the XGBoost Classifier with the Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with the best hyperparameters\n",
    "optimized_xgb = xgb.XGBClassifier(objective='multi:softmax', num_class=3, random_state=42, **best_params) # if accuracy is low, try using softprob next\n",
    "\n",
    "# fit the model\n",
    "optimized_xgb.fit(train_x, train_y)\n",
    "\n",
    "# make predictions\n",
    "y_pred = optimized_xgb.predict(test_x)\n",
    "\n",
    "# model evaluation\n",
    "accuracy = accuracy_score(test_y, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Feature Importance from XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importance from the model\n",
    "feature_names = optimized_xgb.feature_importances_\n",
    "\n",
    "# create a dataframe of feature importances\n",
    "feature_importances = pd.DataFrame({'feature': train_x.columns, 'importance': feature_names})\n",
    "\n",
    "# sort feature importances\n",
    "feature_importances = feature_importances.sort_values(by='importance', ascending=True)\n",
    "\n",
    "# plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importances)\n",
    "plt.title('XGBoost Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Values for Advanced Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain model predictions using SHAP\n",
    "explainer = shap.TreeExplainer(optimized_xgb, train_x)\n",
    "shap_values = explainer.shap_values(test_x)\n",
    "\n",
    "# plot SHAP values\n",
    "shap.summary_plot(shap_values, test_x, plot_type='bar')\n",
    "\n",
    "# detailed SHAP plot\n",
    "shap.summary_plot(shap_values, test_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
